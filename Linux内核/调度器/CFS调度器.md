
# 引言

操作系统中，每时每刻都有着许许多多的进程在执行着，即便是现在最为强大的多核心 CPU，同时能够执行的任务数量也是相当有限的，那么，在这样资源有限的场景下，这么多进程如何来调度，哪些进程更重要哪些进程的执行可以稍微暂缓呢？这就是操作系统调度器的工作。本文我们就来详细介绍一下。

# 进程与调度器

## 操作系统中进程的分类

众所周知，根据进程的运行状态，进程可以被划分为两类：

1.  IO 密集型：频繁 IO，但占用 CPU 的时间不多；
    
2.  CPU 密集型：进程执行过程中很少执行 IO 操作，大部分时间都在占用 CPU 资源执行计算任务。

我们常见的与用户发生交互的程序一般都是 IO 密集型进程，这类进程很少占用 CPU，大部分时间在等待着用户进行操作或者 IO 操作完成，但一旦用户进行了操作，CPU 就必须立即响应，否则就会直接影响到用户的体验，想象一下，你移动了一下鼠标，CPU 由于被 CPU 密集型进程占用着，而让你的鼠标在屏幕上一顿一顿地移动，这显然太过于糟糕。所以 IO 密集型进程的优先级却要高于 CPU 密集型进程。

而非交互式进程通常是需要密集计算的 CPU 密集型进程，这类进程由于不与用户交互，从而在用户无感知的情况下运行，对响应时间的要求也就没有 IO 密集型进程那么高，所以在操作系统中，他们就属于低优先级进程。

## 进程优先级

在操作系统中，同时运行着那么多进程，操作系统是如何确定每个进程的优先级呢？

在 Linux 操作系统中，系统会为每个进程打一个分，这个分就是 PR 值，它是 Priority 的前两个字母。

通过 PR 值的范围，linux 换分出了两类进程：

1.  实时进程 -- PR 值在 0 到 99 之间，PR 值越大，优先级越高；
    
2.  普通进程 -- PR 值在 100 到 139 之间，PR 值越小，优先级越高。
    

但有时，用户可能会不认可操作系统的优先级数值，而是想要去手动调整进程的优先级。此时，如果让用户直接干预 PR 值，那风险就显得很大。Linux 为用户层设计了一个 Nice 值，翻译为“谦让值”。

> PR = PR + Nice

Nice 值取值为 -20 到 19，它的存在让用户得以在一定范围内对 PR 值进行调整。

由于用户能够干预的一般都是普通进程，因此，Nice 值为 0 表示不干预，负值表示增加优先级，正值表示降低优先级。

![[mk.att/Pasted image 20240604144354.png]]

## 操作系统调度策略

在调度进程时，操作系统有两种选择：

1.  协作式调度 -- 进程一旦被调度运行，除非他运行结束或主动释放 CPU，否则它将一直占用 CPU。
    
2.  抢占式调度 -- 进程占用 CPU 的期间可以被其他进程夺走对 CPU 的占用，由操作系统决定每个进程占用 CPU 多久。
    

显然，协作式调度的方式下，执行中的进程一旦想要让出 CPU，它必须自己去保存自己的工作状态，而操作系统所需要做的仅仅是在一个任务让出 CPU 后决定让谁来接替它，这样的设计方式简单而高效，但缺陷也显而易见，一旦一个不那么重要的进程长期霸占 CPU，其他进程都将得不到执行。

而抢占式调度的模式下，操作系统尽管增加了进程切换的开销以及调度算法设计的复杂度，但却可以更加灵活地分配 CPU 的时间资源，所以常见的操作系统一般都采用抢占式调度的策略。

## 调度器设计思路

调度器设计中需要考虑两个重要指标：

1.  周转时间 -- 进程任务从开始排队等待 CPU 资源直到任务完成的时间差。
    
2.  响应时间 -- 进程任务从开始排队等待 CPU 资源直到被调度使用 CPU 的时间差。
    

可以设想，众多等待执行的进程就像是在超市中等待结账的顾客，对他们而言，“响应时间”相当于排队的时间，“周转时间”相当于从开始排队完成结账的时间。对于这些顾客而言，缩短周转时间是他们的核心诉求，但对于超市来说，综合考虑不同顾客对于排队时长的特殊诉求，合理安排所有顾客的排队顺序，才能够降低系统周转时间，拥有良好的用户体验。

综合来说，操作系统的调度原则是：

1.  相较于普通进程，实时进程需要更加优先调度；
    
2.  IO 密集型进程需要频繁调度，以保证缩短响应时间，但单次调度中的执行时长可以缩短，也就是尽量少分配时间片，从而保证系统周转时间的缩短；
    
3.  CPU 密集型进程可以减少调度频率，进而保障 IO 密集型进程的响应，但单次调度中，CPU 密集型进程可以延长执行时长，也就是适当分配较长的时间片，从而提升 CPU 资源的使用率，缩短整体周转时间。

# 调度算法

## 先来先服务算法 FCFS

“先来先服务”翻译自“First Come First Service”，所以缩写为 FCFS，顾名思义，就是让操作系统按照任务到来的顺序顺次执行，很显然，这是各种调度算法设计中最为简单的一个。

这个算法的缺点是显而易见的，一旦此时有一个需要长时间执行的任务被操作系统执行，那么，后续所有的任务都必须等待这个长时间运行的任务执行完毕，假设在操作系统的任务队列中，存在着一个需要执行 30s 的任务，而它后面排队着两个只需执行 10s 的任务，那么这些小任务都需要等待这个长任务运行完成才可以开始执行，极大地**拉长了系统的平均响应时间**，周转时间当然也随之变长。

## 最短任务优先算法 SJF

SJF 是 Shortest Job First 的缩写，还拿上面的例子来说，只要把长任务放在所有短任务之后执行，整个系统的平均响应时间就会变成最优。

具体来看，如果长任务在前，则整体的响应时间为 0s + 30s + 40s = 70s，周转时间为 30s + 40s + 50s = 120s，而如果长任务在最后执行，则整体响应时间为 0s + 10s + 20s = 30s，而整体周转时间为 10s + 20s + 50s = 80s，显然，越是短任务越应该优先执行，这样才能让整个系统的响应时间和周转时间降到最低。

SJF 算法的理想虽然很美好，但在实际系统执行过程中，却往往存在着两个致命的问题：

1.  在进程执行过程中，新的任务随时都有可能到来，如果任务不是同时到来的，那么 SJF 算法事实上就退化成了 FCFS 算法，**无法实现动态调度**。
    
2.  一个进程究竟会运行多久，往往在运行前我们是**无法预测**的。
    

## 抢占式最短任务优先 PSJF

最短任务优先算法看起来很不错，但实际场景中却总是显得过于理想化。要想解决这个问题会稍显复杂。

既然我们无法预知一个进程究竟会执行多久，我们就按顺序先执行第一个进程，当新的任务到来时，操作系统通过预测任务可能的运行时间，来判断新的进程的运行时间是否短于当前正在运行的任务的运行时间，从而决定是否切换到新的进程。这便解决了 SFJ 算法退化的问题。这就是抢占式最短任务优先算法 --Preemptive Shortest Job First。

显然，PSJF 算法的重点在于如何预测新来的任务的运行时长。然而，即便是这个预测是准确的，仍然存在一个很大的问题，假设系统起先执行了一个长任务一段时间后，持续不断地有新的短任务到来，那么，这个长任务将一直被这些短任务抢占，**产生饥饿效应**，结果这个长任务永远都无法得到执行。

## 时间片轮转算法 RR

Round-Robin 算法是现代操作系统调度器诞生的基石。它按照 CPU 时钟芯片产生的若干个时钟脉冲为单位，将 CPU 时间进行切分，每个分片就是 CPU 调度的时间片。

每个进程都以 CPU 时间片为单位进行调度，当时间片的时间到期，如果任务队列中存在其他任务，那么就保存当前进程的上下文并切换到另一个进程再执行一个时间片，如此往复，就可以让每个进程“雨露均沾”地使用到 CPU，**实现了调度算法的公平性**。

![[mk.att/Pasted image 20240604144634.png]]


但上下文的保存和切换并不是无损的，每次上下文切换都需要耗费一定的时间，时间片越短，这浪费掉的额外时间占比也就越大，从而会使整个系统的响应时间和周转时间都被大幅拉升。但如果时间片过大，那么就仍然会出现上述算法所具有的问题，即排在后面的短进程被迫等待排在前面的长进程完成较长的时间片，从而让整个系统的响应时间被随之拉升。

## 多级反馈队列 MLFQ

针对 RR 算法存在的问题，结合上面介绍的 IO 密集型与 CPU 密集型进程的区别：

-   IO 密集型：频繁 IO，但占用 CPU 的时间不多；
    
-   CPU 密集型：进程执行过程中很少执行 IO 操作，大部分时间都在占用 CPU 资源执行计算任务。
    

我们能够得出结论，如果要想降低整体响应时间，那么就需要满足这几个原则：

1.  单个时间片尽量缩短。
    
2.  如果进程是 IO 密集型，那么就频繁调度，但每次调度给与少量时间片。
    
3.  如果进程是 CPU 密集型，那么就降低调度频率，但每次调度给与多个时间片。
    

从这三条原则，我们看出，操作系统必须在运行过程中区分一个进程究竟是 IO 密集型还是 CPU 密集型，并且在正确区分它们的基础上，需要增加优先级概念，从而让 IO 密集型进程更为优先和频繁地被分配到 CPU 时间片，这就需要引入**多级的任务队列**。

但即使有了多级的任务队列，仍然存在着以下几个问题：

1.  怎么保证低优先级的任务不会因为高优先级任务的持续抢占而一直得不到调度。
    
2.  在进程的持续执行中，原本低优先级的 CPU 密集型任务可能在某一时刻变成了 IO 密集型任务，从而需要进入高优先级队列。
    
3.  由于 IO 密集型任务具有更高的优先级，那么进程编写者可能会通过故意进行 IO 操作来骗取操作系统的误判，从而将本是 CPU 密集型的任务被故意包装成 IO 密集型任务，进而被错误地优先调度。
    

所以，光是有多级队列是远远不够的，还需要反馈机制，周期性地对进程类型进行重新评估，避免上述问题。综上，这就是多级反馈队列 Multi-Level Feedback Queue 算法。

![[mk.att/Pasted image 20240604144914.png]]

正是有了多级反馈队列算法，现代生产级操作系统中的进程调度器才得以真正建立起来。

# 调度器历史

## O(n) 调度器

在早期的 linux 操作系统中，2.4 版本到 2.6 版本之间，linux 采用了实现起来十分简单的 O(n) 调度器。

O(n) 调度器只有一个全局的任务队列，即使有多个 CPU，它们也同样共享这个全局的队列。每当有进程就绪，就会被添加到队列，一旦进程运行结束，操作系统就会从队列中删除它。

由于每个进程都拥有自己的优先级，所以每当一个 CPU 执行完一个时间片或空闲时，它只需要遍历整个任务队列，找到优先级最高的一个并执行即可，由于这一遍历过程的时间复杂度为 O(n)，所以这个算法实现的调度器就被命名为 O(n) 调度器。

O(n) 调度器将进程标记为两种基本的类型：

1.  实时进程；
    
2.  非实时进程。

![[mk.att/Pasted image 20240604145156.png]]

### 实时进程的调度

对于实时进程来说，进程必须以高于实时进程的优先级被调用，并且用户不能用 nice 值对这一优先级进行修改。

为了保证实时进程能够得到最高的优先级，操作系统的实现中固定地使用 1000 + 进程的实际优先级来实现对优先级数值的提升，这是一个简单有效的方案。

### 非实时进程的调度

对于绝大多数用户进程来说，它们都是非实时进程，因此，非实时进程的调度是操作系统中最为普遍的。

调度器会按照进程的类型，即它是 CPU 密集型还是 IO 密集型来为进程分配优先级，同时，为了应对进程类型的动态变化以及防止进程为了提升优先级而进行的作弊，操作系统会周期性地重置所有任务的优先级到最高，然后再进行动态调整。

在此基础上，用户还可以为进程分配 nice 值来对优先级进行一定程度上的调整。

这里提到了“周期”，那么这个周期以及动态调整的优先级是怎么实现的呢？它们的答案是同一个东西 -- 时间片。每当一个尚未分配时间片的进程出现在队列中时，调度器都会为这个进程分配固定数量的时间片。而在执行过程中，剩余时间片越多，说明进程 IO 越多，也就说明这个进程是一个 IO 密集型进程，它的调度优先级也就相应的越高。当进程的时间片使用完毕，重复这一过程，意即开启下一周期即可。

而实际上，非实时进程的调度优先级为：

> 时间片剩余数量 + 20 - nice

### O(n) 调度器的缺点

显而易见，上述调度算法存在以下问题：

1.  随着时间片的切换，进程会在不同的 CPU 上执行，因此对 CPU 的**缓存利用率很低**；
    
2.  由于多个 CPU 共享全局队列，因此，当队列中的进程进行增、删、更新时，需要**加锁**，这显然会对整体运行效率造成较大的影响；
    
3.  在队列中，进程无序存放，即使是实时进程也同样混合其中，因此每次寻找下一个执行的进程都需要**遍历整个队列**，性能较低。
    

## O(1) 调度器

在 linux 内核采用 O(n) 调度器的 4 年后，Linux2.6.0 采纳了 Rad Hat 公司设计的 O(1) 调度算法，这是一个基于多级反馈队列算法的调度器实现。

### O(1) 调度器的实现

![[mk.att/Pasted image 20240604145518.png]]

首先，O(1) 调度器最明显的改进是为每个 CPU 都实现了一套队列，并且实现了一套负载均衡算法，每当新的任务到来时，这个负载均衡器会动态决定将进程分配到哪个 CPU 的队列中。

针对每个 CPU，都有两组链表组成两个 hash 表，分别是 active RunQueue 和 expire RunQueue。而每个哈希表中，都通过拉链法维护了 140 个链表，每个槽代表一个优先级，每个链表中的所有任务优先级都相同，因此，调度器可以以 O(1) 时间时间复杂度获取到优先级最高的进程，而为了进一步提升这一过程的执行效率，调度器还通过一个 bitmap 来存储 active 队列各个优先级是否存在任务。

为什么哈希表要拥有 140 个槽呢？因为他们对应了 0~139 这 140 个进程优先级。在 O(1) 调度器中，进程优先级数字越低，实际优先级越高，而 0~99 为实时进程优先级，100~139 为非实时进程优先级。

![[mk.att/Pasted image 20240604145633.png]]

### O(1) 调度器的执行

当 active 队列中某一个进程完成执行，它就会被移动到队列尾部；当队列全部任务都执行过指定时间片以后，bitmap 该优先级对应的位就会被置为 0，当整个 bitmap 全部被置 0 后，调度器指向 active 队列和 expired 队列的指针就会交换，并且重新对已执行过的进程进行优先级重估，并且添加到全新的 active 队列中，开启新的一轮执行。

### O(1) 执行器的缺点

当然了，O(1) 执行器也存在一些缺点：

1.  IO 密集型任务的识别**准确率欠佳**，尤其是与 O(n) 简单粗暴的实现方式相比，并且随着时间的推移，这类问题暴露的也越来越多，直到到了积重难返的地步；
2.  avtive 队列和 expire 队列交换的过程虽然简单快捷，但**重新评估优先级仍然存在一定的耗时**。

## CFS 调度器

由于 O(1) 调度器的上述问题，很快在 Linux 2.6.23 版本，就有一款新的调度器 -- CFS 被内核采用，它是由匈牙利程序员 Ingo Molnar 在澳大利亚外科医生 Con Kolivas 提出的楼梯调度算法基础上改进实现的。

这其中还有一个有趣的轶事，作为外科医生的 Con Kolivas 在完成他的楼梯调度算法的设计后，开发实现了一款名为 RSDL 的调度器，意即公平策略调度器（The Rotating Staircase Deadline Schedule），然而，这个调度器被 Linus 无情地拒绝了，这让 Con Kolivas 十分不满，他愤而退出了 Linux 内核开发社区，并且在此后开发了 BFS，意即“脑残调度器”（Brain Fuck Scheduler）来发泄自己的不满。

### 调度器分层思想

而事实证明，在公平策略调度器基础上改进设计的 CFS 确实是一款优秀的调度器，它的思想是将调度器进行模块化，从而让操作系统中可以有多种调度器以不同的策略和优先级来执行。

这样一来，CFS 再也不用去关心实时进程了，它只需要专注于普通进程即可，这也就是“让最适合的调度器，去做最适合的事”。

操作系统中，调度器由此分为四层：

1.  DL 调度器：采用 sched_deadline 策略；
    
2.  RT 调度器：采用 sched_rr 和 sched_fifo 策略；
    
3.  CFS 调度器：采用 sched_normal 和 sched_batch 策略；
    
4.  IDEL 调度器：采用 sched_idle 策略。
    

### CFS 调度器的实现

CFS 调度器的思想是“完全公平”，可是显然，不同优先级的进程实际执行的物理时间是不同的，那么，怎么算是公平的呢？

CFS 调度器提出了“虚拟运行时间”的概念：

> 虚拟运行时间 = 物理运行时间 * nice 值对应的权重 / 优先级对应的权重

这里有一个“权重”的概念，在 CFS 调度器中，维护了一个与普通进程优先级 100~139 一一对应的 40 个权重组成的列表：

```
const int sched_prio_to_weight[40] = {	88761,     71755,     56483,     46273,     36291,	29154,     23254,     18705,     14949,     11916,	 9548,      7620,      6100,      4904,      3906,	 3121,      2501,      1991,      1586,      1277,	 1024,       820,       655,       526,       423,	  335,       272,       215,       172,       137,	  110,        87,        70,        56,        45,	   36,        29,        23,        18,        15,};
```

在保证公平，即所有进程虚拟运行时间相同的前提下，通过上述计算，优先级对应的权重值越大，实际的物理运行时间也就越长。

这个算法让物理运行时间在不同优先级的进程中发生不同程度的膨胀，从而实现了虚拟运行时间上的完全公平，这样一来，在系统负载高时，任务可以**仍然在保证公平的前提下对其物理执行时间进行伸缩**，这是 O(1) 调度器和 O(n) 调度器这类通过分配固定时间片的调度器所不能实现的。

### CFS 调度器的 pick-next 算法

CFS 调度器的执行过程与其选取下一个将要执行的任务的 pick-next 算法所依赖的数据结构息息相关，那就是 -- 红黑树。

红黑树拥有很强的自适应性，我们知道，有序的二叉树都有一个致命的弱点，那就是增、删、更新操作时，需要进行 rebalance，这是一个十分耗时的操作，例如在 AVL 树中，删除节点时，整个树结构的旋转次数都是 O(logN) 量级的，而红黑树则在最坏情况下只需要进行三次旋转，而增加节点时，红黑树则只需要至多进行两次旋转。

同时，红黑树虽然并不保证平衡，但它保证了有序，在 CFS 调度器中，pick-next 的红黑树中，key 是任务已经执行过的虚拟运行时间，这样一来，在公平原则的前提下，调度器只需要每次都选取最左子树的左叶子结点进行执行，也就是每次都去执行已经运行虚拟运行时间最少的进程，这当然就是最公平的。

## Linux调度类

调度策略 RHEL6 ( Linux 2.6.32 ）中定义下列调度策略。

实时调度：

- SCHED_FIFO  高优先级可以抢占低优先级，相同优先级 先来先服务
- SCHED_RR 相同优先级，轮流时间片服务
- SCHED_DEADLINE 根据deadline进行，选择deadline最近的那个任务

普通调度策略：

- SCHED_OTHER 普通进程
- SCHED_BATCH 后台进程，优先级低于普通进程
- SCHED_IDLE  只有cpu idle 的时候才执行

下面将分别对各调度策略进行介绍。

### SCHED OTHER

这是 Linux 的标准调度策略，也是所谓 TSS 调度策略。

在 RHEL5 等 Linux 2.6.23之前的内核所使用的以优先级为基础的O（1）调度程序中，还加入了经脸性的判断，优先为会话进程赋予执行权。 TSS的时间片由优先级决定．

在 RHEL6 等 Linux 2.6.23之后的 CFS 调度器中．会公平地为所有 TSS 策略的进程分配 CPU 时间。其时间片是动态决定的．

### SCHED FIFO

这是实时调度策略．即具有动态优先级的调度策略。 Linux 内核中能够为实时调度策略的进程指定的优先级为 1-99。使用了 SCHED _ FIFO 调度策略的进程，除了等待 I/O 完成时休眠、自发休眠或优先级更高的实时进程获得优先权以外，不会释放执行权。

使用 SCHEO_FIFO 的实时调度策略时，需要注意的是．它的进程不会自动释放CPU . 也就是说执行权不会转移到其他进程。例如．实时调度该略的进程陷入无限循环时．其他所有优先级较低的进程永远不会被赋予执行权．此时系统就会死机。

### SCHED_RR

这也是实时调度策略． RR 是轮询的缩写，与 SCHED＿FIFO 不同的是．它具有时间片。时间片使用完时．执行权将转移到其他进程。在 2.6 .23 以前导人的 O（1）调度程序中，时间片是由优先级决定的。

引入CFS时SCHED _ RR的调度策略也进行了修改，时间片变为固定值 （100毫秒）。

### SCHED_BATC

指定这个调度策略的进程不是会话型，不会根据休眠时间更改优先级。例如，备份处理等需要进行较大文件或大量文件存取的进程，是通过磁盘I/O来中止的。在 TSS 调度策略中，因为这个休眠，正在进行备份处理的进程优先级提高，需要应答性的shell等的优先级相对降低。这就会导致系统的应答性降低。

在 RHEL5的 O（1）调度程序中．使用了这个调度策略的进程被识别为休眼时间为0的 CPU bound进程。因此，优先级必然会变成比会话型shell进程低。

对非会话型的进程（即所谓的补丁处理）使用这个调度策略，就可以使会话型进程的优先级保持相对较高，并确保应答性．

在 Linux 2.6.23 导入的 CFS 中，对进行补丁处理的进程改变了处理的方法，优先级不会因休眠时间而发生变化。在导入 CFS 的 RHEL6 中． SCHEO_BATCH 和 SCHEO_OTHER 几乎没有区别．因此可以不使用。

### SCHED_IDLE

这是由 CFS 导人的新等级。 CPU 空闲时，即 SCHEO_IDLE 等级以外处于可执行状态的进程消失时，将被赋予执行权。也就是它将成为优先级最低的进程。

特殊标志： SCHED_RESET_0N_FORK

为了限制实时调度策略的进程运行，而为调度策略添加了标志flag，设置了标志flag的实时调度策略进程．在执行fork时．新生成的子进程就成为SCHED_OTHER策略的进程。

### 小结

Linux 代码中有5个实现，

-   stop_sched_class 优先级最高的任务会使用这种策略，会中断所有其他线程，且不会被其他任务打断；
    
-   dl_sched_class 就对应上面的 deadline 调度策略；
    
-   rt_sched_class 就对应 RR 算法或者 FIFO 算法的调度策略，具体调度策略由进程的 task_struct->policy 指定；
    
-   fair_sched_class 就是普通进程的调度策略；
    
-   idle_sched_class 就是空闲进程的调度策略
    

实际调度代码会挨个调用这些class

## 进程和线程的区别

#### 内存

-   进程：不共享内存
-   线程：共享进程的内存空间

#### 作用

-   进程：是 CPU 资源分配的最小单位，它主要用来就是资源的分配
-   线程：是 CPU 调度执行的最小单位，它主要用来系统调度

#### 资源

进程共享系统的文件、网络资源，而线程会共享进程的资源文件

#### 独立

-   进程：独立存在，有自己的内存地址
-   线程：不可以独立，必须依赖进程而存在

#### 开销

-   进程：需要分配内存，开销较大
-   线程：只需要分配栈和一个 PC，开销比较小

#### 通信

-   进程：进程间通信比较复杂，因为它的数据空间独立性，需要通过操作系统，基于 socket 的进程间的通信机制
-   线程：线程间的通信由于多线程共享内存地址空间和数据空间，可直接通信，不必通过操作系统（内核的调度），比较简单

#### 影响关系

-   进程：进程崩溃之后，在系统保护模式下，不会对其他进程产生影响
-   线程：一个线程崩溃之后，整个进程都会死掉
-   总结：多进程比多线程要健壮


- 进程状态
	- R
		- Running
		- 进程在CPU的就绪队列中，正在运行或者正在等待运行
	- D
		- Disk Sleep
		- 不可中断状态睡眠
		- 进程正在跟硬件交互，并且交互过程不允许被其他进程或中断打断
	- Z
		- Zombie
		- 进程已经结束，但父进程没有回收资源
	- S
		- Interruptible Sleep
		- 可中断状态睡眠
		- 进程因为等待某个事件而被系统挂起
	- I
		- Idle
		- 不可中断睡眠的内核线程
		- 与D对应，但并不会导致平均负载升高

## 小结

本文介绍了 linux 操作系统中的调度器和调度算法的演进，这当然是非常大略的介绍，有兴趣还是建议去阅读相关的内核源码，这里包括对操作系统调度器实际使用的辅助性的数据结构的缺省，都是为了提高文章可读性的需要，实际上，在操作系统中仍然有大量的细节，和许多调度器实际遇到的问题的解决值得我们深入地进一步研究。

# 相关工具

- cgroup
	- 限制进程的资源使用；
- chrt
	- 修改进程的调度策略和优先级；

